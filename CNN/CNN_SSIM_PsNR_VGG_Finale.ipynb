{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff0fe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18.5\n",
      "2.3.1\n",
      "4.5.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "print(np.__version__)\n",
    "print(tf.__version__)\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d94d47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorlayer as tl\n",
    "\n",
    "def PSNR(y_true, y_pred):\n",
    "    max_pixel = 1.0\n",
    "    return (10.0 * K.log((max_pixel ** 2) / (K.mean(K.square(y_pred - y_true), axis=-1)))) / 2.303\n",
    "def compute_psnr(original_image, generated_image):\n",
    "    original_image = tf.convert_to_tensor(original_image, dtype = tf.float32)\n",
    "    generated_image = tf.convert_to_tensor(generated_image, dtype = tf.float32)\n",
    "    psnr = tf.image.psnr(original_image, generated_image, max_val = 1.0)\n",
    "    return tf.math.reduce_mean(psnr, axis = None, keepdims = False, name = None)\n",
    "def compute_ssim(original_image, generated_image):\n",
    "    original_image = tf.convert_to_tensor(original_image, dtype = tf.float32)\n",
    "    generated_image = tf.convert_to_tensor(generated_image, dtype = tf.float32)\n",
    "    ssim = tf.image.ssim(original_image, generated_image, max_val = 1.0, filter_size = 11, filter_sigma = 1.5, k1 = 0.01, )\n",
    "    return tf.math.reduce_mean(ssim, axis = None, keepdims = False, name = None)\n",
    "def vgg_19_loss_4(original_image, generated_image):\n",
    "    original_image = tf.convert_to_tensor(original_image, dtype = tf.float32)\n",
    "    generated_image = tf.convert_to_tensor(generated_image, dtype = tf.float32)\n",
    "    original_image_vgg = new_vgg(original_image)\n",
    "    generated_image_vgg = new_vgg(generated_image)\n",
    "    vgg_loss = 3e-5*tl.cost.mean_squared_error(generated_image_vgg,original_image_vgg,is_mean=True)\n",
    "    return vgg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5883893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18.5\n",
      "2.3.1\n",
      "4.5.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "print(np.__version__)\n",
    "print(tf.__version__)\n",
    "print(cv2.__version__)\n",
    "\n",
    "def load_data(path,size):\n",
    "    high_res_images = []\n",
    "    low_res_images = []\n",
    "    count = 0\n",
    "    for (dirname, _, filenames_high_res),(dirname, _, filenames_low_res) in zip(os.walk(path+'HIGH'),os.walk(path+'LOW')):\n",
    "        filenames_high_res.sort()\n",
    "        filenames_low_res.sort()\n",
    "        \n",
    "        for filename_high,filename_low in zip(filenames_high_res,filenames_low_res):\n",
    "            #faulty image\n",
    "            \n",
    "            try:\n",
    "                count+=1\n",
    "                img = cv2.imread(os.path.join(dirname, filename_high))\n",
    "                img_2 = cv2.imread(os.path.join(dirname, filename_low))\n",
    "                # resizing the images\n",
    "                width=int(img.shape[1])\n",
    "                height=int(img.shape[0])\n",
    "                \n",
    "                width_2= int(img_2.shape[1])\n",
    "                height_2=int(img_2.shape[0]) \n",
    "            \n",
    "                if width!= 512 and height !=512:\n",
    "                    dsize=(512,512)\n",
    "                    img=cv2.resize(img,dsize)\n",
    "                  \n",
    "                if width_2!= 256 and height_2 !=256:\n",
    "                    dsize=(256,256)\n",
    "                    dsize_1 = (128,128)\n",
    "                    img_2 = cv2.resize(img_2,dsize_1,interpolation=cv2.INTER_AREA)\n",
    "                    img_2 = cv2.resize(img_2,dsize,interpolation=cv2.INTER_AREA)\n",
    "                    #img_2=cv2.resize(img_2,dsize)\n",
    "                    img_2 = np.array(img_2)+ np.random.rand(256,256,3)*50\n",
    "                \n",
    "                img = process_image(img)\n",
    "                img_2 = process_image(img_2)\n",
    "                high_res_images.append(img)\n",
    "                low_res_images.append(img_2)\n",
    "            except:\n",
    "                continue\n",
    "            if count >size:\n",
    "                break\n",
    "    \n",
    "    # zero-mean and zero-center the standard deviations ....\n",
    "    low_res_array = np.array(low_res_images)\n",
    "    #mean_centered_low_res = (low_res_array - low_res_array.mean())/low_res_array.std()\n",
    "    \n",
    "    # zero-mean and zero-center the standard deviations .....\n",
    "    high_res_array = np.array(high_res_images)\n",
    "    #mean_centered_high_res = (high_res_array - high_res_array.mean())/high_res_array.std()\n",
    "    \n",
    "    \n",
    "    #return mean_centered_low_res, mean_centered_high_res\n",
    "    return low_res_array,high_res_array\n",
    "\n",
    "def process_image(image):\n",
    "    return image/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38bcc3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = ''\n",
    "train_x, train_y =  load_data(path=base_dir+'Training/',size=7000)\n",
    "val_x, val_y = load_data(path=base_dir+'Validationing/',size=7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a25c73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 256, 256, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e89d186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 256, 256, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "608a7829",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3,3,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5e97caa6ad64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mvgg_19\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mvgg_19\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/applications/vgg19.py\u001b[0m in \u001b[0;36mVGG19\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    169\u001b[0m       512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n\u001b[1;32m    170\u001b[0m   x = layers.Conv2D(\n\u001b[0;32m--> 171\u001b[0;31m       512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n\u001b[0m\u001b[1;32m    172\u001b[0m   x = layers.Conv2D(\n\u001b[1;32m    173\u001b[0m       512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2641\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2643\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2644\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    143\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                         shape=None):\n\u001b[1;32m    198\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2596\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2597\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2598\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2599\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1516\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1649\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[0;32m-> 1651\u001b[0;31m                 \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1652\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[1;32m   1653\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    395\u001b[0m        \u001b[0;34m(\u001b[0m\u001b[0mvia\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_floatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \"\"\"\n\u001b[0;32m--> 397\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVarianceScaling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_get_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1042\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     return op(\n\u001b[0;32m-> 1044\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m       result = gen_random_ops.random_uniform(\n\u001b[0;32m--> 302\u001b[0;31m           shape, dtype, seed=seed1, seed2=seed2)\n\u001b[0m\u001b[1;32m    303\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mminval_is_zero\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaxval_is_one\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/gen_random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[1;32m    724\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]"
     ]
    }
   ],
   "source": [
    "## The fully convolutional encoder-decoder network and then creating a new loss function with the VGG_19 loss\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, UpSampling2D, add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "vgg_19 = tf.keras.applications.VGG19(include_top=False,weights='imagenet',input_shape=(512,512,3),pooling=None)\n",
    "vgg_19.summary()\n",
    "\n",
    "new_vgg = Model(inputs= vgg_19.input,outputs=vgg_19.get_layer('block5_conv4').output)\n",
    "new_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad37b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import tensorflow.keras as keras\n",
    "## The fully convolutional encoder-decoder network and then creating a new loss function with the VGG_19 loss\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, UpSampling2D, add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "input_img = Input(shape=(256, 256, 3))\n",
    "l1 = Conv2D(64, (3, 3), padding='same', activation='elu', bias_initializer='zeros',\n",
    "            activity_regularizer=regularizers.l1(10e-10),kernel_initializer=tf.compat.v1.keras.initializers.glorot_normal(seed=None,dtype=tf.dtypes.float32))(input_img)\n",
    "l2 = Conv2D(64, (3, 3), padding='same', activation='elu', bias_initializer='zeros',\n",
    "            activity_regularizer=regularizers.l1(10e-10),kernel_initializer=tf.compat.v1.keras.initializers.glorot_normal(seed=None,dtype=tf.dtypes.float32))(l1)\n",
    "#print('This is the l2\\'s shape {}'.format(l2.shape))\n",
    "\n",
    "l3 = MaxPooling2D(padding='same')(l2)\n",
    "#print(l3.shape)\n",
    "l3 = BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001)(l3)\n",
    "#l3 = Dropout(0.3)(l3)\n",
    "l4 = Conv2D(128, (3, 3),  padding='same', activation='elu', bias_initializer='zeros',\n",
    "            activity_regularizer=regularizers.l1(10e-10),kernel_initializer=tf.compat.v1.keras.initializers.glorot_normal(seed=None,dtype=tf.dtypes.float32))(l3)\n",
    "l5 = Conv2D(128, (3, 3), padding='same', activation='elu', bias_initializer='zeros',\n",
    "            activity_regularizer=regularizers.l1(10e-10),kernel_initializer=tf.compat.v1.keras.initializers.glorot_normal(seed=None,dtype=tf.dtypes.float32))(l4)\n",
    "#print('This is L5 shape {}'.format(l5.shape))\n",
    "\n",
    "l6 = MaxPooling2D(padding='same')(l5)\n",
    "#l6 = Dropout(0.3)(l6)\n",
    "l6 = BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001)(l6)\n",
    "l7 = Conv2D(256, (3, 3), padding='same', activation='elu', bias_initializer='zeros',\n",
    "            activity_regularizer=regularizers.l1(10e-10),kernel_initializer=tf.compat.v1.keras.initializers.glorot_normal(seed=None,dtype=tf.dtypes.float32))(l6)\n",
    "#print('This is L7 shape {}'.format(l7.shape))\n",
    "#l8 = UpSampling2D()(l7)\n",
    "l8 = Conv2DTranspose(128,(1,1),padding='same',strides=(2,2),activation='elu',bias_initializer='zeros',activity_regularizer=regularizers.l1(10e-10),\n",
    "                    kernel_initializer=tf.compat.v1.keras.initializers.glorot_normal(seed=None,dtype=tf.dtypes.float32),data_format='channels_last')(l7)\n",
    "# increasing the stide to 2,2 enables upsampling of the images\n",
    "#print('This is L8 shape {}'.format(l8.shape))\n",
    "l8 = BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001)(l8)\n",
    "#l8 = Dropout(0.3)(l8)\n",
    "l9 = Conv2D(128, (3, 3), padding='same', activation='elu',bias_initializer='zeros',\n",
    "            activity_regularizer=regularizers.l1(10e-10),kernel_initializer=tf.compat.v1.keras.initializers.glorot_normal(seed=None,dtype=tf.dtypes.float32))(l8)\n",
    "l10 = Conv2D(128, (3, 3), padding='same', activation='elu',bias_initializer='zeros',\n",
    "             activity_regularizer=regularizers.l1(10e-10),kernel_initializer=tf.compat.v1.keras.initializers.glorot_normal(seed=None,dtype=tf.dtypes.float32))(l9)\n",
    "#l10 = BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001)(l10)\n",
    "l10 = Dropout(0.3)(l10)\n",
    "\n",
    "l11 = add([l5, l10])\n",
    "\n",
    "#print('This is the l11 shape {}'.format(l11.shape))\n",
    "#l12 = UpSampling2D()(l11)\n",
    "l12 = Conv2DTranspose(128,(2,2),padding='same',strides=(2,2),activation='elu',bias_initializer='zeros',activity_regularizer=regularizers.l1(10e-10),\n",
    "                    kernel_initializer=tf.compat.v1.keras.initializers.glorot_normal(seed=None,dtype=tf.dtypes.float32),data_format='channels_last')(l11)\n",
    "\n",
    "#print('This is the l12\\'s shape {}'.format(l12.shape))\n",
    "\n",
    "l13 = Conv2D(64, (3, 3), padding='same', activation='elu',bias_initializer='zeros',\n",
    "             activity_regularizer=regularizers.l1(10e-10),kernel_initializer=tf.compat.v1.keras.initializers.glorot_normal(seed=None,dtype=tf.dtypes.float32))(l12)\n",
    "l14 = Conv2D(64, (3, 3), padding='same', activation='elu',\n",
    "             activity_regularizer=regularizers.l1(10e-10),kernel_initializer=tf.compat.v1.keras.initializers.glorot_normal(seed=None,dtype=tf.dtypes.float32))(l13)\n",
    "\n",
    "#l14 = BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001)(l14)\n",
    "l14 = Dropout(0.3)(l14)\n",
    "l15 = add([l14, l2])\n",
    "l16 = Conv2DTranspose(64,(2,2),padding='same',strides=(2,2),activation='elu',bias_initializer='zeros',activity_regularizer=regularizers.l1(10e-10),\n",
    "                    kernel_initializer=tf.compat.v1.keras.initializers.glorot_normal(seed=None,dtype=tf.dtypes.float32),data_format='channels_last')(l15)\n",
    "\n",
    "decoded = Conv2D(3, (3, 3), padding='same', activation='elu', bias_initializer='zeros',\n",
    "                 activity_regularizer=regularizers.l1(10e-10),kernel_initializer=tf.compat.v1.keras.initializers.glorot_normal(seed=None,dtype=tf.dtypes.float32))(l16)\n",
    "\n",
    "\n",
    "    \n",
    "model = Model(input_img, decoded)\n",
    "    #model.compile(optimizer=keras.optimizers.Adam(1e-4), loss='mean_squared_error')\n",
    "    #model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c3a45d",
   "metadata": {},
   "source": [
    "## NO VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9cadd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Show the VAE function\n",
    "### Modifying the train_step\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import tensorflow.keras as keras\n",
    "## The fully convolutional encoder-decoder network and then creating a new loss function with the VGG_19 loss\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, UpSampling2D, add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow as tf\n",
    "\n",
    "class VGG(keras.Model):\n",
    "    def __init__(self, decoder,compute_psnr,compute_sims, **kwargs):\n",
    "        super(VGG, self).__init__(**kwargs)\n",
    "        self.decoder = decoder\n",
    "        self.compute_psnr = compute_psnr\n",
    "        self.compute_ssim = compute_sims\n",
    "        #self.vgg_loss = vgg_loss\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        #self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        #self.vgg_loss_tracker = keras.metrics.Mean(name=\"vgg_loss\")\n",
    "        self.ssim_tracker = keras.metrics.Mean(name='ssim_loss')\n",
    "        self.psnr_tracker = keras.metrics.Mean(name='psnr_loss')\n",
    "        \n",
    "        self.val_total_loss_tracker = keras.metrics.Mean(name=\"val_total_loss\")\n",
    "        #self.val_reconstruction_loss_tracker = keras.metrics.Mean(name=\"val_reconstruction_loss\")\n",
    "        #self.val_vgg_loss_tracker = keras.metrics.Mean(name=\"val_vgg_loss\")\n",
    "        self.val_ssim_tracker = keras.metrics.Mean(name='val_ssim_loss')\n",
    "        self.val_psnr_tracker = keras.metrics.Mean(name='val_psnr_loss')\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.ssim_tracker,\n",
    "            self.psnr_tracker\n",
    "            #self.reconstruction_loss_tracker,\n",
    "            #self.vgg_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def call(self, data, training = False):\n",
    "        \n",
    "        reconstruction = self.decoder(data) # data is a tuple of encoder_inputs,dim_encoding_2,latent_ratio\n",
    "        return reconstruction\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            train_x,pred_x = data\n",
    "            reconstruction = self.decoder(train_x) # data is a tuple of encoder_inputs,dim_encoding_2,latent_ratio\n",
    "            \n",
    "            reconstruction_loss = tf.keras.losses.MSE(pred_x,reconstruction)\n",
    "            psnr_loss = self.compute_psnr(pred_x,reconstruction)\n",
    "            ssim_loss = self.compute_ssim(pred_x,reconstruction)\n",
    "            \n",
    "            \n",
    "        grads = tape.gradient(reconstruction_loss, self.decoder.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.decoder.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.ssim_tracker.update_state(ssim_loss)\n",
    "        self.psnr_tracker.update_state(psnr_loss)\n",
    "        return {\n",
    "            \"total_loss\": self.total_loss_tracker.result(),\n",
    "            \"ssim_loss\": self.ssim_tracker.result(),\n",
    "            \"psnr_loss\": self.psnr_tracker.result()\n",
    "        }\n",
    "    \n",
    "    def test_step(self,data):\n",
    "        test_x,pred_x = data\n",
    "        y_pred = self(test_x,training=False)\n",
    "        #print(y_pred)\n",
    "        #z_mean,z_log_var,_,reconstruction = self.decoder(data)\n",
    "        reconstruction_loss = tf.keras.losses.MSE(pred_x,y_pred)\n",
    "        psnr_loss = self.compute_psnr(pred_x,y_pred)\n",
    "        ssim_loss = self.compute_ssim(pred_x,y_pred)    \n",
    "        total_loss = reconstruction_loss\n",
    "        \n",
    "        self.val_total_loss_tracker.update_state(total_loss)\n",
    "        self.val_ssim_tracker.update_state(ssim_loss)\n",
    "        self.val_psnr_tracker.update_state(psnr_loss)\n",
    "        \n",
    "        return {\"val_total_loss\": self.val_total_loss_tracker.result(),\n",
    "                \"val_ssim_loss\": self.val_ssim_tracker.result(),\n",
    "                \"val_psnr_loss\": self.val_psnr_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bd5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modifying the train_step\n",
    "class VGG(keras.Model):\n",
    "    def __init__(self, decoder,compute_psnr,compute_sims,vgg_loss, **kwargs):\n",
    "        super(VGG, self).__init__(**kwargs)\n",
    "        self.decoder = decoder\n",
    "        self.vgg_loss = vgg_loss\n",
    "        self.compute_psnr = compute_psnr\n",
    "        self.compute_ssim = compute_sims\n",
    "        \n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.vgg_loss_tracker = keras.metrics.Mean(name=\"vgg_loss\")\n",
    "        self.ssim_tracker = keras.metrics.Mean(name='ssim_loss')\n",
    "        self.psnr_tracker = keras.metrics.Mean(name='psnr_loss')\n",
    "        \n",
    "        self.val_total_loss_tracker = keras.metrics.Mean(name=\"val_total_loss\")\n",
    "        self.val_reconstruction_loss_tracker = keras.metrics.Mean(name=\"val_reconstruction_loss\")\n",
    "        self.val_vgg_loss_tracker = keras.metrics.Mean(name=\"val_vgg_loss\")\n",
    "        self.val_ssim_tracker = keras.metrics.Mean(name='val_ssim_loss')\n",
    "        self.val_psnr_tracker = keras.metrics.Mean(name='val_psnr_loss')\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.vgg_loss_tracker,\n",
    "            self.ssim_tracker,\n",
    "            self.psnr_tracker]\n",
    "    \n",
    "    def call(self, data, training = False):\n",
    "        if training:\n",
    "            train_x,train_y=data\n",
    "            reconstruction = self.decoder(train_x) # data is a tuple of encoder_inputs,dim_encoding_2,latent_ratio\n",
    "        else:\n",
    "            reconstruction= self.decoder(data)\n",
    "            return (reconstruction)\n",
    "        return reconstruction\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            #print(data)\n",
    "            train_x,pred_x = data\n",
    "            reconstruction = self.decoder(train_x) # data is a tuple of encoder_inputs,dim_encoding_2,latent_ratio\n",
    "            reconstruction_loss = tf.keras.losses.MSE(pred_x,reconstruction)\n",
    "            # vgg loss computation\n",
    "            vgg_losss = self.vgg_loss(pred_x)\n",
    "            recon = self.vgg_loss(reconstruction)\n",
    "            \n",
    "            vgg_loss = 3e-3*tl.cost.mean_squared_error(vgg_losss,recon,is_mean=True)\n",
    "            #vgg_loss = 3e-5*tf.reduce_mean(tf.keras.losses.MSE(vgg_losss,recon))\n",
    "            \n",
    "            \n",
    "            #vgg_loss = self.vgg_algo(self.vgg_loss,pred_x,reconstruction)\n",
    "            psnr_loss = self.compute_psnr(pred_x,reconstruction)\n",
    "            ssim_loss = self.compute_ssim(pred_x,reconstruction)\n",
    "            \n",
    "            \n",
    "            \n",
    "            total_loss = reconstruction_loss + vgg_loss\n",
    "        grads = tape.gradient(total_loss, self.decoder.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.decoder.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.vgg_loss_tracker.update_state(vgg_loss)\n",
    "        self.ssim_tracker.update_state(ssim_loss)\n",
    "        self.psnr_tracker.update_state(psnr_loss)\n",
    "        return {\n",
    "            \"total_loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"vgg_loss\": self.vgg_loss_tracker.result(),\n",
    "            \"ssim_loss\": self.ssim_tracker.result(),\n",
    "            \"psnr_loss\": self.psnr_tracker.result()\n",
    "            }\n",
    "    \n",
    "    def test_step(self,data):\n",
    "        test_x,pred_x = data\n",
    "        y_pred = self(test_x,training=False)\n",
    "        #print(y_pred)\n",
    "        #z_mean,z_log_var,_,reconstruction = self.decoder(data)\n",
    "        reconstruction_loss = tf.keras.losses.MSE(y_pred,pred_x)\n",
    "        psnr_loss = self.compute_psnr(pred_x,y_pred)\n",
    "        ssim_loss = self.compute_ssim(pred_x,y_pred)\n",
    "        ## vgg loss computation\n",
    "        \n",
    "        vgg_losss = self.vgg_loss(pred_x)\n",
    "        recon = self.vgg_loss(y_pred)\n",
    "        #vgg_loss = 3e-5*tf.reduce_mean(tf.keras.losses.MSE(vgg_losss,recon))\n",
    "        vgg_loss = 3e-3*tl.cost.mean_squared_error(vgg_losss,recon,is_mean=True)\n",
    "        \n",
    "        #vgg_loss = self.vgg_algo(self.vgg_loss,pred_x,y_pred)\n",
    "        total_loss = reconstruction_loss + vgg_loss\n",
    "        self.val_total_loss_tracker.update_state(total_loss)\n",
    "        self.val_reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.val_vgg_loss_tracker.update_state(vgg_loss)\n",
    "        self.val_ssim_tracker.update_state(ssim_loss)\n",
    "        self.val_psnr_tracker.update_state(psnr_loss)\n",
    "        \n",
    "        return {\"total_loss\": self.val_total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.val_reconstruction_loss_tracker.result(),\n",
    "            \"vgg_loss\": self.val_vgg_loss_tracker.result(),\n",
    "            \"val_ssim_loss\": self.val_ssim_tracker.result(),\n",
    "            \"val_psnr_loss\": self.val_psnr_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_8 = VGG(model,compute_psnr,compute_ssim,vgg_19)\n",
    "model_6 = VGG(model,compute_psnr,compute_ssim)\n",
    "model_6.compile(optimizer=keras.optimizers.Adam(1e-3),loss=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c7ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_10= model_6.fit(train_x, train_y, validation_data =(val_x , val_y),epochs = 20, batch_size = 12, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd277f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8.save('CNN_04_31_SIMS_PSNR_VGG_512_DropOut_TheBest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792fdd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten= model_8.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceef70e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30,30))\n",
    "plt.figure(figsize=(40,40))\n",
    "ax1.imshow(val_x[100])\n",
    "ax1.title.set_text(\"low-res image \")\n",
    "ax2.imshow(val_y[100])\n",
    "ax2.title.set_text(\"high-res image \")\n",
    "ax3.imshow(ten[100])\n",
    "ax3.title.set_text(\"model's output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a945989",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30,30))\n",
    "plt.figure(figsize=(40,40))\n",
    "ax1.imshow(val_x[200])\n",
    "ax1.title.set_text(\"low-res image \")\n",
    "ax2.imshow(val_y[200])\n",
    "ax2.title.set_text(\"high-res image \")\n",
    "ax3.imshow(ten[200])\n",
    "ax3.title.set_text(\"model's output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bcc2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "plt.plot(history_10.history['total_loss'])\n",
    "plt.plot(history_10.history['val_total_loss'])\n",
    "#plt.plot(history_5.history['kl_loss'][1:])\n",
    "plt.title('CNN MSE Loss curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['total train-loss','total_val_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fa328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "plt.plot(history_10.history['vgg_loss'])\n",
    "plt.plot(history_10.history['val_vgg_loss'])\n",
    "#plt.plot(history_5.history['kl_loss'][1:])\n",
    "plt.title('CNN MSE Loss curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train-vgg-loss','val-vgg-loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e06f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "plt.plot(history_10.history['ssim_loss'])\n",
    "plt.plot(history_10.history['val_val_ssim_loss'])\n",
    "#plt.plot(history_5.history['kl_loss'][1:])\n",
    "plt.title('CNN MSE Loss curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['ssim-loss','val-ssim-loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ec980",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "plt.plot(history_10.history['psnr_loss'])\n",
    "plt.plot(history_10.history['val_val_psnr_loss'])\n",
    "#plt.plot(history_5.history['kl_loss'][1:])\n",
    "plt.title('CNN MSE Loss curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['psnr-loss','val-ssim-loss'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
